{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4797c347",
   "metadata": {},
   "source": [
    "### original test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313e5ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xnli (/home/s6amalia/.cache/huggingface/datasets/xnli/default-language=en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, I wasn't even thinking about that, but I...</td>\n",
       "      <td>I havent spoken to him again.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, I wasn't even thinking about that, but I...</td>\n",
       "      <td>I was so upset that I just started talking to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, I wasn't even thinking about that, but I...</td>\n",
       "      <td>We had a great talk.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And I thought that was a privilege, and it's s...</td>\n",
       "      <td>I was not aware that I was not the only person...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And I thought that was a privilege, and it's s...</td>\n",
       "      <td>I was under the impression that I was the only...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>Davidson should not adopt the pronunciation of...</td>\n",
       "      <td>Davidson shouldn't talk in a way where bone an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>Davidson should not adopt the pronunciation of...</td>\n",
       "      <td>It would be better if Davidson rhymed the word...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>The average novel of 200,000 words for $25 wor...</td>\n",
       "      <td>A 200,000 word novel at $25 is a fair price.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>The average novel of 200,000 words for $25 wor...</td>\n",
       "      <td>A 200,000 word novel for $25 is 4,000 words pe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>The average novel of 200,000 words for $25 wor...</td>\n",
       "      <td>A 200,000 word novel for $25 is 8,000 words pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5010 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                premise  \\\n",
       "0     Well, I wasn't even thinking about that, but I...   \n",
       "1     Well, I wasn't even thinking about that, but I...   \n",
       "2     Well, I wasn't even thinking about that, but I...   \n",
       "3     And I thought that was a privilege, and it's s...   \n",
       "4     And I thought that was a privilege, and it's s...   \n",
       "...                                                 ...   \n",
       "5005  Davidson should not adopt the pronunciation of...   \n",
       "5006  Davidson should not adopt the pronunciation of...   \n",
       "5007  The average novel of 200,000 words for $25 wor...   \n",
       "5008  The average novel of 200,000 words for $25 wor...   \n",
       "5009  The average novel of 200,000 words for $25 wor...   \n",
       "\n",
       "                                             hypothesis  label  \n",
       "0                         I havent spoken to him again.      2  \n",
       "1     I was so upset that I just started talking to ...      0  \n",
       "2                                  We had a great talk.      1  \n",
       "3     I was not aware that I was not the only person...      1  \n",
       "4     I was under the impression that I was the only...      0  \n",
       "...                                                 ...    ...  \n",
       "5005  Davidson shouldn't talk in a way where bone an...      0  \n",
       "5006  It would be better if Davidson rhymed the word...      2  \n",
       "5007       A 200,000 word novel at $25 is a fair price.      1  \n",
       "5008  A 200,000 word novel for $25 is 4,000 words pe...      2  \n",
       "5009  A 200,000 word novel for $25 is 8,000 words pe...      0  \n",
       "\n",
       "[5010 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "language = 'en'\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset('xnli', split='test',language=language)\n",
    "df_test = pd.DataFrame(dataset)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbf4562",
   "metadata": {},
   "source": [
    "### Test data with typo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589e8cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Well, i wasn't event thinking about that, but...</td>\n",
       "      <td>'I havent spoke to him again.'</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Well, I wasn't even thinking about that, but ...</td>\n",
       "      <td>'I was so upset that I just started talkng to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Well, I wasn't even thinking Pabout that, but...</td>\n",
       "      <td>'We had an great talk.'</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'And I thought that was a privilege, and it's ...</td>\n",
       "      <td>'i was not aware that I was not the only perso...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'And I thought that was a privilege, and it's ...</td>\n",
       "      <td>'I was Under the impression that I is the only...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>'Davidson would not adopt the pronunciation of...</td>\n",
       "      <td>'Davidson shouldn't talk in a way where bone A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>'Davidson should not adopt the pronunciation o...</td>\n",
       "      <td>'It would be better if Davison rhymed the word...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>'The average novel of 200,000 words for $25 Wo...</td>\n",
       "      <td>'A 200,000 word novel at $25 is of fair price.'</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>'The average Novel of 200,000 words for $25 wo...</td>\n",
       "      <td>'A 200,000 word novel for $25 id 4,000 words p...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>'The average novel of 200,000 words for $25 wo...</td>\n",
       "      <td>'A 200,000 word novel for $25 is 8,000 word pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5010 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                premise  \\\n",
       "0     'Well, i wasn't event thinking about that, but...   \n",
       "1     'Well, I wasn't even thinking about that, but ...   \n",
       "2     'Well, I wasn't even thinking Pabout that, but...   \n",
       "3     'And I thought that was a privilege, and it's ...   \n",
       "4     'And I thought that was a privilege, and it's ...   \n",
       "...                                                 ...   \n",
       "5005  'Davidson would not adopt the pronunciation of...   \n",
       "5006  'Davidson should not adopt the pronunciation o...   \n",
       "5007  'The average novel of 200,000 words for $25 Wo...   \n",
       "5008  'The average Novel of 200,000 words for $25 wo...   \n",
       "5009  'The average novel of 200,000 words for $25 wo...   \n",
       "\n",
       "                                             hypothesis  label  \n",
       "0                        'I havent spoke to him again.'      2  \n",
       "1     'I was so upset that I just started talkng to ...      0  \n",
       "2                               'We had an great talk.'      1  \n",
       "3     'i was not aware that I was not the only perso...      1  \n",
       "4     'I was Under the impression that I is the only...      0  \n",
       "...                                                 ...    ...  \n",
       "5005  'Davidson shouldn't talk in a way where bone A...      0  \n",
       "5006  'It would be better if Davison rhymed the word...      2  \n",
       "5007    'A 200,000 word novel at $25 is of fair price.'      1  \n",
       "5008  'A 200,000 word novel for $25 id 4,000 words p...      2  \n",
       "5009  'A 200,000 word novel for $25 is 8,000 word pe...      0  \n",
       "\n",
       "[5010 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DATA_DIR = r\"/home/s6amalia/thesis/\"\n",
    "df_typo = pd.read_table(DATA_DIR+'test_'+language+'_typos_0.05.tsv')\n",
    "df_typo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab7fa1d",
   "metadata": {},
   "source": [
    "### Number of typos in each sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db012857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "def typo_count(s1,s2):\n",
    "    \n",
    "    # Create a Differ object\n",
    "    differ = difflib.Differ()\n",
    "\n",
    "    # Compare the two texts line by line\n",
    "    diff = list(differ.compare(s1.splitlines(), s2.splitlines()))\n",
    "    num_changes = sum(1 for line in diff if line.startswith('-') or line.startswith('+'))\n",
    "    return num_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "667d76bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "typos = []\n",
    "for i in range(len(dftest)):\n",
    "    s2 = df_typo['premise'].iloc[i][1:-1]\n",
    "    s1 = dftest['sentence1'].iloc[i]\n",
    "    typos.append(typo_count(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6686f5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typo_count(dftest['sentence1'].iloc[4000],df_typo['premise'].iloc[4000][1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3f9446",
   "metadata": {},
   "source": [
    "### Find original test data corresponding to the typo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7658d9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows 656 of 658\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix1 = vectorizer.fit_transform(df_typo['hypothesis'])\n",
    "tfidf_matrix2 = vectorizer.transform(df_de['hypothesis'])\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix1, tfidf_matrix2)\n",
    "\n",
    "# Threshold for considering texts as similar\n",
    "threshold = 0.77\n",
    "\n",
    "# Find similar rows\n",
    "similar_rows = []\n",
    "for i in range(len(df_typo)):\n",
    "    for j in range(len(df_de)):\n",
    "        if cosine_sim[i, j] > threshold:\n",
    "            similar_rows.append((i, j))\n",
    "columns = df_de.columns\n",
    "similar_df = []\n",
    "\n",
    "for pair in similar_rows:\n",
    "    similar_df.append(df_de.iloc[pair[1]])\n",
    "df_test = pd.DataFrame(similar_df)   \n",
    "\n",
    "print('Found',len(df_test),'of', len(df_typo))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f656df6",
   "metadata": {},
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fa3ce6",
   "metadata": {},
   "source": [
    "### Predict labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc41870b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    'They told me that, uh, that I would be called of a guy at the end for me to meet.'\n",
       "7    'They told me that, uh, that I would be called in A guy at the end for me to meet.'\n",
       "8    'They told me that, uh, that I would be called in a guy as the end for me to meet.'\n",
       "Name: premise, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pd.options.display.max_colwidth = 300\n",
    "df['premise'][6:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "055cadb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a312439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaConfig {\n",
       "  \"_name_or_path\": \"joeddav/xlm-roberta-large-xnli\",\n",
       "  \"architectures\": [\n",
       "    \"XLMRobertaForSequenceClassification\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 1024,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"contradiction\",\n",
       "    \"1\": \"neutral\",\n",
       "    \"2\": \"entailment\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4096,\n",
       "  \"label2id\": {\n",
       "    \"contradiction\": 0,\n",
       "    \"entailment\": 2,\n",
       "    \"neutral\": 1\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"xlm-roberta\",\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.32.1\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 250002\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"joeddav/xlm-roberta-large-xnli\"\n",
    "# model_name = \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name ,token='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',use_fast=False)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,token='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')\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f4fb3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,XLMRobertaForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"/home/s6amalia/xlmroberta-xnli.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1caf5061",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict_labels(df):\n",
    "    all_pred = []\n",
    "    for i in range(len(df)):\n",
    "        premise = df['premise'].iloc[i]\n",
    "        hypothesis = df['hypothesis'].iloc[i]\n",
    "        input = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "        output = model(input[\"input_ids\"].to(device))  # device = \"cuda:0\" or \"cpu\"\n",
    "#         print(output)\n",
    "        prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "        label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "        # prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "        all_pred.append(prediction.index(max(prediction)))\n",
    "        print(int(i*100/len(df)),'%', end='\\r')\n",
    "    print(round( accuracy_score(all_pred, df['label'])*100,2))   \n",
    "    return all_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4022c551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d899cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.41\n"
     ]
    }
   ],
   "source": [
    "all_pred = predict_labels(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "017b1c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.28\n"
     ]
    }
   ],
   "source": [
    "all_pred = predict_labels(df_typo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
