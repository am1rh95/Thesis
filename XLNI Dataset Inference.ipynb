{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f9067a",
   "metadata": {},
   "source": [
    "### original test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4fde015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xnli (/home/s6amalia/.cache/huggingface/datasets/xnli/default-language=en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, I wasn't even thinking about that, but I...</td>\n",
       "      <td>I havent spoken to him again.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, I wasn't even thinking about that, but I...</td>\n",
       "      <td>I was so upset that I just started talking to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, I wasn't even thinking about that, but I...</td>\n",
       "      <td>We had a great talk.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And I thought that was a privilege, and it's s...</td>\n",
       "      <td>I was not aware that I was not the only person...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And I thought that was a privilege, and it's s...</td>\n",
       "      <td>I was under the impression that I was the only...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>Davidson should not adopt the pronunciation of...</td>\n",
       "      <td>Davidson shouldn't talk in a way where bone an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>Davidson should not adopt the pronunciation of...</td>\n",
       "      <td>It would be better if Davidson rhymed the word...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>The average novel of 200,000 words for $25 wor...</td>\n",
       "      <td>A 200,000 word novel at $25 is a fair price.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>The average novel of 200,000 words for $25 wor...</td>\n",
       "      <td>A 200,000 word novel for $25 is 4,000 words pe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>The average novel of 200,000 words for $25 wor...</td>\n",
       "      <td>A 200,000 word novel for $25 is 8,000 words pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5010 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                premise  \\\n",
       "0     Well, I wasn't even thinking about that, but I...   \n",
       "1     Well, I wasn't even thinking about that, but I...   \n",
       "2     Well, I wasn't even thinking about that, but I...   \n",
       "3     And I thought that was a privilege, and it's s...   \n",
       "4     And I thought that was a privilege, and it's s...   \n",
       "...                                                 ...   \n",
       "5005  Davidson should not adopt the pronunciation of...   \n",
       "5006  Davidson should not adopt the pronunciation of...   \n",
       "5007  The average novel of 200,000 words for $25 wor...   \n",
       "5008  The average novel of 200,000 words for $25 wor...   \n",
       "5009  The average novel of 200,000 words for $25 wor...   \n",
       "\n",
       "                                             hypothesis  label  \n",
       "0                         I havent spoken to him again.      2  \n",
       "1     I was so upset that I just started talking to ...      0  \n",
       "2                                  We had a great talk.      1  \n",
       "3     I was not aware that I was not the only person...      1  \n",
       "4     I was under the impression that I was the only...      0  \n",
       "...                                                 ...    ...  \n",
       "5005  Davidson shouldn't talk in a way where bone an...      0  \n",
       "5006  It would be better if Davidson rhymed the word...      2  \n",
       "5007       A 200,000 word novel at $25 is a fair price.      1  \n",
       "5008  A 200,000 word novel for $25 is 4,000 words pe...      2  \n",
       "5009  A 200,000 word novel for $25 is 8,000 words pe...      0  \n",
       "\n",
       "[5010 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "language = 'en'\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset('xnli', split='test',language=language)\n",
    "df_test = pd.DataFrame(dataset)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67a9f9b",
   "metadata": {},
   "source": [
    "### Test data with typo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4368e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Well, i wasn't event thinking about that, but...</td>\n",
       "      <td>'I havent spoke to him again.'</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Well, I wasn't even thinking about that, but ...</td>\n",
       "      <td>'I was so upset that I just started talkng to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Well, I wasn't even thinking Pabout that, but...</td>\n",
       "      <td>'We had an great talk.'</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'And I thought that was a privilege, and it's ...</td>\n",
       "      <td>'i was not aware that I was not the only perso...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'And I thought that was a privilege, and it's ...</td>\n",
       "      <td>'I was Under the impression that I is the only...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>'Davidson would not adopt the pronunciation of...</td>\n",
       "      <td>'Davidson shouldn't talk in a way where bone A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>'Davidson should not adopt the pronunciation o...</td>\n",
       "      <td>'It would be better if Davison rhymed the word...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>'The average novel of 200,000 words for $25 Wo...</td>\n",
       "      <td>'A 200,000 word novel at $25 is of fair price.'</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>'The average Novel of 200,000 words for $25 wo...</td>\n",
       "      <td>'A 200,000 word novel for $25 id 4,000 words p...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>'The average novel of 200,000 words for $25 wo...</td>\n",
       "      <td>'A 200,000 word novel for $25 is 8,000 word pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5010 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                premise  \\\n",
       "0     'Well, i wasn't event thinking about that, but...   \n",
       "1     'Well, I wasn't even thinking about that, but ...   \n",
       "2     'Well, I wasn't even thinking Pabout that, but...   \n",
       "3     'And I thought that was a privilege, and it's ...   \n",
       "4     'And I thought that was a privilege, and it's ...   \n",
       "...                                                 ...   \n",
       "5005  'Davidson would not adopt the pronunciation of...   \n",
       "5006  'Davidson should not adopt the pronunciation o...   \n",
       "5007  'The average novel of 200,000 words for $25 Wo...   \n",
       "5008  'The average Novel of 200,000 words for $25 wo...   \n",
       "5009  'The average novel of 200,000 words for $25 wo...   \n",
       "\n",
       "                                             hypothesis  label  \n",
       "0                        'I havent spoke to him again.'      2  \n",
       "1     'I was so upset that I just started talkng to ...      0  \n",
       "2                               'We had an great talk.'      1  \n",
       "3     'i was not aware that I was not the only perso...      1  \n",
       "4     'I was Under the impression that I is the only...      0  \n",
       "...                                                 ...    ...  \n",
       "5005  'Davidson shouldn't talk in a way where bone A...      0  \n",
       "5006  'It would be better if Davison rhymed the word...      2  \n",
       "5007    'A 200,000 word novel at $25 is of fair price.'      1  \n",
       "5008  'A 200,000 word novel for $25 id 4,000 words p...      2  \n",
       "5009  'A 200,000 word novel for $25 is 8,000 word pe...      0  \n",
       "\n",
       "[5010 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = r\"/home/s6amalia/thesis/\"\n",
    "df_typo = pd.read_table(DATA_DIR+'test_'+language+'_typos_0.05.tsv')\n",
    "df_typo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c5154c",
   "metadata": {},
   "source": [
    "### Find original test data corresponding to the typo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bc2a16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 682 of 687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix1 = vectorizer.fit_transform(df_typo['hypothesis'])\n",
    "tfidf_matrix2 = vectorizer.transform(df_test['hypothesis'])\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix1, tfidf_matrix2)\n",
    "\n",
    "# Threshold for considering texts as similar; change it to find the best number of data\n",
    "threshold = 0.81\n",
    "\n",
    "# Find similar rows\n",
    "similar_rows = []\n",
    "for i in range(len(df_typo)):\n",
    "    for j in range(len(df_test)):\n",
    "        if cosine_sim[i, j] > threshold:\n",
    "            similar_rows.append((i, j))\n",
    "columns = df_test.columns\n",
    "similar_df = []\n",
    "\n",
    "for pair in similar_rows:\n",
    "    similar_df.append(df_test.iloc[pair[1]])\n",
    "df_test_1 = pd.DataFrame(similar_df)   \n",
    "\n",
    "print('Found',len(df_test_1),'of', len(df_typo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c095636f",
   "metadata": {},
   "source": [
    "### Number of typos in each sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a31562ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "def typo_count(s1,s2):\n",
    "    \n",
    "    # Create a Differ object\n",
    "    differ = difflib.Differ()\n",
    "\n",
    "    # Compare the two texts line by line\n",
    "    diff = list(differ.compare(s1.splitlines(), s2.splitlines()))\n",
    "    num_changes = sum(1 for line in diff if line.startswith('-') or line.startswith('+'))\n",
    "    return num_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36fd43c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "typos = []\n",
    "for i in range(len(df_test)):\n",
    "    s2 = df_typo['premise'].iloc[i][1:-1]\n",
    "    s1 = df_test['premise'].iloc[i]\n",
    "    typos.append(typo_count(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2e1dd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typo_count(df_test['premise'].iloc[4000],df_typo['premise'].iloc[4000][1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0a8f54",
   "metadata": {},
   "source": [
    "### Predict labels and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1625a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a375875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,XLMRobertaForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "## loading the fine-tuned model\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"/home/s6amalia/xlmroberta-xnli.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac1209e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(df):\n",
    "    all_pred = []\n",
    "    for i in range(len(df)):\n",
    "        premise = df['premise'].iloc[i]\n",
    "        hypothesis = df['hypothesis'].iloc[i]\n",
    "        input = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "        output = model(input[\"input_ids\"].to(device))  # device = \"cuda:0\" or \"cpu\"\n",
    "#         print(output)\n",
    "        prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "        label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "        # prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "        all_pred.append(prediction.index(max(prediction)))\n",
    "        print(int(i*100/len(df)),'%', end='\\r')\n",
    "    print(round( accuracy_score(all_pred, df['label'])*100,2))   \n",
    "    return all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2126701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.43\n"
     ]
    }
   ],
   "source": [
    "all_pred = predict_labels(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66c03df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.75\n"
     ]
    }
   ],
   "source": [
    "all_pred = predict_labels(df_typo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
